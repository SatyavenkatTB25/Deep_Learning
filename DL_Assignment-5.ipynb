{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement #1:**\n",
        "Build a sequential model to classify names into gender.\n",
        "\n",
        "Input to the model will be a name, i.e. a sequence of characters.\n",
        "\n",
        "Use one hot representation of the  characters.\n",
        "\n",
        "Remove non-ascii characters, if there are any\n",
        "\n"
      ],
      "metadata": {
        "id": "7vijELFd59g_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eubzyl5-9ABp",
        "outputId": "6992b307-72d7-4028-c0c1-ab42ea18e57f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "297/297 - 9s - 29ms/step - accuracy: 0.8028 - loss: 0.4280 - val_accuracy: 0.7879 - val_loss: 0.4613\n",
            "Epoch 2/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8654 - loss: 0.3265 - val_accuracy: 0.8718 - val_loss: 0.3112\n",
            "Epoch 3/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8811 - loss: 0.2960 - val_accuracy: 0.8830 - val_loss: 0.2912\n",
            "Epoch 4/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8915 - loss: 0.2705 - val_accuracy: 0.8773 - val_loss: 0.2987\n",
            "Epoch 5/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8992 - loss: 0.2537 - val_accuracy: 0.8832 - val_loss: 0.2772\n",
            "Epoch 6/10\n",
            "297/297 - 2s - 6ms/step - accuracy: 0.9072 - loss: 0.2364 - val_accuracy: 0.8906 - val_loss: 0.2743\n",
            "Epoch 7/10\n",
            "297/297 - 3s - 9ms/step - accuracy: 0.9130 - loss: 0.2194 - val_accuracy: 0.8952 - val_loss: 0.2662\n",
            "Epoch 8/10\n",
            "297/297 - 2s - 6ms/step - accuracy: 0.9210 - loss: 0.2036 - val_accuracy: 0.8973 - val_loss: 0.2561\n",
            "Epoch 9/10\n",
            "297/297 - 1s - 5ms/step - accuracy: 0.9284 - loss: 0.1888 - val_accuracy: 0.8973 - val_loss: 0.2749\n",
            "Epoch 10/10\n",
            "297/297 - 3s - 9ms/step - accuracy: 0.9289 - loss: 0.1864 - val_accuracy: 0.8998 - val_loss: 0.2823\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "Epoch 1/10\n",
            "297/297 - 9s - 30ms/step - accuracy: 0.7554 - loss: 0.4925 - val_accuracy: 0.8302 - val_loss: 0.3994\n",
            "Epoch 2/10\n",
            "297/297 - 5s - 17ms/step - accuracy: 0.8479 - loss: 0.3556 - val_accuracy: 0.8535 - val_loss: 0.3507\n",
            "Epoch 3/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8571 - loss: 0.3367 - val_accuracy: 0.8582 - val_loss: 0.3361\n",
            "Epoch 4/10\n",
            "297/297 - 1s - 5ms/step - accuracy: 0.8617 - loss: 0.3271 - val_accuracy: 0.8605 - val_loss: 0.3220\n",
            "Epoch 5/10\n",
            "297/297 - 2s - 8ms/step - accuracy: 0.8671 - loss: 0.3178 - val_accuracy: 0.8611 - val_loss: 0.3252\n",
            "Epoch 6/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8706 - loss: 0.3077 - val_accuracy: 0.8674 - val_loss: 0.3099\n",
            "Epoch 7/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8754 - loss: 0.2973 - val_accuracy: 0.8758 - val_loss: 0.3010\n",
            "Epoch 8/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8812 - loss: 0.2877 - val_accuracy: 0.8765 - val_loss: 0.2928\n",
            "Epoch 9/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8883 - loss: 0.2751 - val_accuracy: 0.8838 - val_loss: 0.2924\n",
            "Epoch 10/10\n",
            "297/297 - 1s - 4ms/step - accuracy: 0.8930 - loss: 0.2647 - val_accuracy: 0.8857 - val_loss: 0.2908\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Epoch 1/10\n",
            "297/297 - 8s - 27ms/step - accuracy: 0.7685 - loss: 0.4801 - val_accuracy: 0.8491 - val_loss: 0.3618\n",
            "Epoch 2/10\n",
            "297/297 - 2s - 6ms/step - accuracy: 0.8526 - loss: 0.3438 - val_accuracy: 0.8561 - val_loss: 0.3448\n",
            "Epoch 3/10\n",
            "297/297 - 2s - 8ms/step - accuracy: 0.8596 - loss: 0.3318 - val_accuracy: 0.8634 - val_loss: 0.3249\n",
            "Epoch 4/10\n",
            "297/297 - 3s - 10ms/step - accuracy: 0.8641 - loss: 0.3202 - val_accuracy: 0.8666 - val_loss: 0.3155\n",
            "Epoch 5/10\n",
            "297/297 - 2s - 7ms/step - accuracy: 0.8693 - loss: 0.3097 - val_accuracy: 0.8596 - val_loss: 0.3296\n",
            "Epoch 6/10\n",
            "297/297 - 1s - 5ms/step - accuracy: 0.8749 - loss: 0.3008 - val_accuracy: 0.8678 - val_loss: 0.3085\n",
            "Epoch 7/10\n",
            "297/297 - 1s - 5ms/step - accuracy: 0.8773 - loss: 0.2951 - val_accuracy: 0.8697 - val_loss: 0.3126\n",
            "Epoch 8/10\n",
            "297/297 - 2s - 6ms/step - accuracy: 0.8834 - loss: 0.2836 - val_accuracy: 0.8779 - val_loss: 0.2950\n",
            "Epoch 9/10\n",
            "297/297 - 2s - 5ms/step - accuracy: 0.8872 - loss: 0.2724 - val_accuracy: 0.8809 - val_loss: 0.2866\n",
            "Epoch 10/10\n",
            "297/297 - 3s - 10ms/step - accuracy: 0.8925 - loss: 0.2623 - val_accuracy: 0.8805 - val_loss: 0.2841\n",
            "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Epoch 1/10\n",
            "594/594 - 7s - 11ms/step - accuracy: 0.8145 - loss: 0.4070 - val_accuracy: 0.8542 - val_loss: 0.3445\n",
            "Epoch 2/10\n",
            "594/594 - 7s - 12ms/step - accuracy: 0.8652 - loss: 0.3247 - val_accuracy: 0.8663 - val_loss: 0.3165\n",
            "Epoch 3/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.8786 - loss: 0.2954 - val_accuracy: 0.8671 - val_loss: 0.3192\n",
            "Epoch 4/10\n",
            "594/594 - 3s - 4ms/step - accuracy: 0.8883 - loss: 0.2743 - val_accuracy: 0.8769 - val_loss: 0.2904\n",
            "Epoch 5/10\n",
            "594/594 - 3s - 5ms/step - accuracy: 0.8972 - loss: 0.2553 - val_accuracy: 0.8827 - val_loss: 0.2862\n",
            "Epoch 6/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.9006 - loss: 0.2418 - val_accuracy: 0.8825 - val_loss: 0.2801\n",
            "Epoch 7/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.9086 - loss: 0.2282 - val_accuracy: 0.8886 - val_loss: 0.2763\n",
            "Epoch 8/10\n",
            "594/594 - 3s - 4ms/step - accuracy: 0.9123 - loss: 0.2172 - val_accuracy: 0.8873 - val_loss: 0.2756\n",
            "Epoch 9/10\n",
            "594/594 - 3s - 5ms/step - accuracy: 0.9157 - loss: 0.2091 - val_accuracy: 0.8937 - val_loss: 0.2622\n",
            "Epoch 10/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.9205 - loss: 0.1984 - val_accuracy: 0.8934 - val_loss: 0.2629\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "594/594 - 9s - 15ms/step - accuracy: 0.7830 - loss: 0.4565 - val_accuracy: 0.8369 - val_loss: 0.3747\n",
            "Epoch 2/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.8441 - loss: 0.3592 - val_accuracy: 0.8343 - val_loss: 0.3749\n",
            "Epoch 3/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.8544 - loss: 0.3391 - val_accuracy: 0.8500 - val_loss: 0.3426\n",
            "Epoch 4/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.8622 - loss: 0.3203 - val_accuracy: 0.8620 - val_loss: 0.3243\n",
            "Epoch 5/10\n",
            "594/594 - 3s - 4ms/step - accuracy: 0.8716 - loss: 0.3028 - val_accuracy: 0.8677 - val_loss: 0.3114\n",
            "Epoch 6/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.8781 - loss: 0.2910 - val_accuracy: 0.8653 - val_loss: 0.3099\n",
            "Epoch 7/10\n",
            "594/594 - 2s - 4ms/step - accuracy: 0.8842 - loss: 0.2797 - val_accuracy: 0.8784 - val_loss: 0.2940\n",
            "Epoch 8/10\n",
            "594/594 - 3s - 4ms/step - accuracy: 0.8887 - loss: 0.2678 - val_accuracy: 0.8772 - val_loss: 0.2900\n",
            "Epoch 9/10\n",
            "594/594 - 3s - 5ms/step - accuracy: 0.8954 - loss: 0.2553 - val_accuracy: 0.8827 - val_loss: 0.2880\n",
            "Epoch 10/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.8990 - loss: 0.2455 - val_accuracy: 0.8845 - val_loss: 0.2730\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "594/594 - 9s - 15ms/step - accuracy: 0.7972 - loss: 0.4366 - val_accuracy: 0.8409 - val_loss: 0.3668\n",
            "Epoch 2/10\n",
            "594/594 - 6s - 10ms/step - accuracy: 0.8466 - loss: 0.3573 - val_accuracy: 0.8495 - val_loss: 0.3485\n",
            "Epoch 3/10\n",
            "594/594 - 3s - 6ms/step - accuracy: 0.8565 - loss: 0.3351 - val_accuracy: 0.8551 - val_loss: 0.3369\n",
            "Epoch 4/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.8644 - loss: 0.3212 - val_accuracy: 0.8566 - val_loss: 0.3345\n",
            "Epoch 5/10\n",
            "594/594 - 5s - 9ms/step - accuracy: 0.8716 - loss: 0.3067 - val_accuracy: 0.8666 - val_loss: 0.3126\n",
            "Epoch 6/10\n",
            "594/594 - 3s - 6ms/step - accuracy: 0.8781 - loss: 0.2924 - val_accuracy: 0.8666 - val_loss: 0.3190\n",
            "Epoch 7/10\n",
            "594/594 - 3s - 5ms/step - accuracy: 0.8845 - loss: 0.2780 - val_accuracy: 0.8768 - val_loss: 0.2927\n",
            "Epoch 8/10\n",
            "594/594 - 5s - 9ms/step - accuracy: 0.8907 - loss: 0.2650 - val_accuracy: 0.8867 - val_loss: 0.2864\n",
            "Epoch 9/10\n",
            "594/594 - 5s - 9ms/step - accuracy: 0.8961 - loss: 0.2522 - val_accuracy: 0.8884 - val_loss: 0.2745\n",
            "Epoch 10/10\n",
            "594/594 - 5s - 8ms/step - accuracy: 0.9033 - loss: 0.2395 - val_accuracy: 0.8901 - val_loss: 0.2760\n",
            "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "891/891 - 7s - 8ms/step - accuracy: 0.8209 - loss: 0.3995 - val_accuracy: 0.8593 - val_loss: 0.3390\n",
            "Epoch 2/10\n",
            "891/891 - 4s - 4ms/step - accuracy: 0.8659 - loss: 0.3218 - val_accuracy: 0.8653 - val_loss: 0.3247\n",
            "Epoch 3/10\n",
            "891/891 - 3s - 4ms/step - accuracy: 0.8763 - loss: 0.2939 - val_accuracy: 0.8774 - val_loss: 0.2860\n",
            "Epoch 4/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.8874 - loss: 0.2739 - val_accuracy: 0.8659 - val_loss: 0.3280\n",
            "Epoch 5/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.8936 - loss: 0.2591 - val_accuracy: 0.8852 - val_loss: 0.2762\n",
            "Epoch 6/10\n",
            "891/891 - 5s - 5ms/step - accuracy: 0.8997 - loss: 0.2468 - val_accuracy: 0.8875 - val_loss: 0.2838\n",
            "Epoch 7/10\n",
            "891/891 - 3s - 4ms/step - accuracy: 0.9044 - loss: 0.2346 - val_accuracy: 0.8751 - val_loss: 0.2891\n",
            "Epoch 8/10\n",
            "891/891 - 4s - 4ms/step - accuracy: 0.9094 - loss: 0.2233 - val_accuracy: 0.8899 - val_loss: 0.2684\n",
            "Epoch 9/10\n",
            "891/891 - 5s - 5ms/step - accuracy: 0.9115 - loss: 0.2170 - val_accuracy: 0.8912 - val_loss: 0.2604\n",
            "Epoch 10/10\n",
            "891/891 - 3s - 4ms/step - accuracy: 0.9164 - loss: 0.2095 - val_accuracy: 0.8926 - val_loss: 0.2712\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Epoch 1/10\n",
            "891/891 - 8s - 9ms/step - accuracy: 0.8016 - loss: 0.4269 - val_accuracy: 0.8344 - val_loss: 0.3718\n",
            "Epoch 2/10\n",
            "891/891 - 7s - 8ms/step - accuracy: 0.8455 - loss: 0.3543 - val_accuracy: 0.8473 - val_loss: 0.3455\n",
            "Epoch 3/10\n",
            "891/891 - 3s - 4ms/step - accuracy: 0.8575 - loss: 0.3309 - val_accuracy: 0.8549 - val_loss: 0.3280\n",
            "Epoch 4/10\n",
            "891/891 - 4s - 4ms/step - accuracy: 0.8672 - loss: 0.3124 - val_accuracy: 0.8648 - val_loss: 0.3094\n",
            "Epoch 5/10\n",
            "891/891 - 4s - 4ms/step - accuracy: 0.8752 - loss: 0.2953 - val_accuracy: 0.8711 - val_loss: 0.3067\n",
            "Epoch 6/10\n",
            "891/891 - 5s - 5ms/step - accuracy: 0.8821 - loss: 0.2812 - val_accuracy: 0.8632 - val_loss: 0.3143\n",
            "Epoch 7/10\n",
            "891/891 - 6s - 6ms/step - accuracy: 0.8898 - loss: 0.2650 - val_accuracy: 0.8828 - val_loss: 0.2769\n",
            "Epoch 8/10\n",
            "891/891 - 5s - 5ms/step - accuracy: 0.8960 - loss: 0.2525 - val_accuracy: 0.8890 - val_loss: 0.2637\n",
            "Epoch 9/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.9008 - loss: 0.2393 - val_accuracy: 0.8914 - val_loss: 0.2598\n",
            "Epoch 10/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.9068 - loss: 0.2275 - val_accuracy: 0.8936 - val_loss: 0.2632\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "891/891 - 10s - 12ms/step - accuracy: 0.8094 - loss: 0.4144 - val_accuracy: 0.8400 - val_loss: 0.3654\n",
            "Epoch 2/10\n",
            "891/891 - 7s - 8ms/step - accuracy: 0.8483 - loss: 0.3505 - val_accuracy: 0.8456 - val_loss: 0.3528\n",
            "Epoch 3/10\n",
            "891/891 - 4s - 5ms/step - accuracy: 0.8587 - loss: 0.3296 - val_accuracy: 0.8591 - val_loss: 0.3254\n",
            "Epoch 4/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.8678 - loss: 0.3103 - val_accuracy: 0.8631 - val_loss: 0.3421\n",
            "Epoch 5/10\n",
            "891/891 - 5s - 6ms/step - accuracy: 0.8754 - loss: 0.2933 - val_accuracy: 0.8751 - val_loss: 0.2970\n",
            "Epoch 6/10\n",
            "891/891 - 4s - 5ms/step - accuracy: 0.8837 - loss: 0.2768 - val_accuracy: 0.8721 - val_loss: 0.2971\n",
            "Epoch 7/10\n",
            "891/891 - 6s - 6ms/step - accuracy: 0.8905 - loss: 0.2616 - val_accuracy: 0.8793 - val_loss: 0.2860\n",
            "Epoch 8/10\n",
            "891/891 - 5s - 5ms/step - accuracy: 0.8973 - loss: 0.2474 - val_accuracy: 0.8848 - val_loss: 0.2687\n",
            "Epoch 9/10\n",
            "891/891 - 4s - 5ms/step - accuracy: 0.9027 - loss: 0.2338 - val_accuracy: 0.8882 - val_loss: 0.2662\n",
            "Epoch 10/10\n",
            "891/891 - 6s - 7ms/step - accuracy: 0.9091 - loss: 0.2209 - val_accuracy: 0.8912 - val_loss: 0.2626\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "1188/1188 - 11s - 9ms/step - accuracy: 0.8289 - loss: 0.3858 - val_accuracy: 0.8565 - val_loss: 0.3357\n",
            "Epoch 2/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8682 - loss: 0.3137 - val_accuracy: 0.8691 - val_loss: 0.3080\n",
            "Epoch 3/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8796 - loss: 0.2891 - val_accuracy: 0.8746 - val_loss: 0.2990\n",
            "Epoch 4/10\n",
            "1188/1188 - 4s - 3ms/step - accuracy: 0.8902 - loss: 0.2693 - val_accuracy: 0.8772 - val_loss: 0.2980\n",
            "Epoch 5/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8965 - loss: 0.2546 - val_accuracy: 0.8840 - val_loss: 0.2751\n",
            "Epoch 6/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.9012 - loss: 0.2428 - val_accuracy: 0.8861 - val_loss: 0.2745\n",
            "Epoch 7/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.9056 - loss: 0.2338 - val_accuracy: 0.8942 - val_loss: 0.2675\n",
            "Epoch 8/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.9094 - loss: 0.2259 - val_accuracy: 0.8921 - val_loss: 0.2630\n",
            "Epoch 9/10\n",
            "1188/1188 - 4s - 3ms/step - accuracy: 0.9115 - loss: 0.2185 - val_accuracy: 0.8838 - val_loss: 0.2974\n",
            "Epoch 10/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.9158 - loss: 0.2110 - val_accuracy: 0.8928 - val_loss: 0.2609\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "1188/1188 - 10s - 9ms/step - accuracy: 0.8163 - loss: 0.4062 - val_accuracy: 0.8431 - val_loss: 0.3598\n",
            "Epoch 2/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8496 - loss: 0.3467 - val_accuracy: 0.8549 - val_loss: 0.3368\n",
            "Epoch 3/10\n",
            "1188/1188 - 5s - 5ms/step - accuracy: 0.8602 - loss: 0.3241 - val_accuracy: 0.8613 - val_loss: 0.3226\n",
            "Epoch 4/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8709 - loss: 0.3056 - val_accuracy: 0.8694 - val_loss: 0.3006\n",
            "Epoch 5/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8804 - loss: 0.2851 - val_accuracy: 0.8777 - val_loss: 0.2861\n",
            "Epoch 6/10\n",
            "1188/1188 - 5s - 5ms/step - accuracy: 0.8870 - loss: 0.2709 - val_accuracy: 0.8835 - val_loss: 0.2752\n",
            "Epoch 7/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8936 - loss: 0.2572 - val_accuracy: 0.8867 - val_loss: 0.2698\n",
            "Epoch 8/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.9008 - loss: 0.2420 - val_accuracy: 0.8905 - val_loss: 0.2575\n",
            "Epoch 9/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.9055 - loss: 0.2307 - val_accuracy: 0.8949 - val_loss: 0.2550\n",
            "Epoch 10/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.9109 - loss: 0.2178 - val_accuracy: 0.8971 - val_loss: 0.2505\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "1188/1188 - 12s - 10ms/step - accuracy: 0.8166 - loss: 0.4017 - val_accuracy: 0.8426 - val_loss: 0.3592\n",
            "Epoch 2/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8500 - loss: 0.3472 - val_accuracy: 0.8542 - val_loss: 0.3364\n",
            "Epoch 3/10\n",
            "1188/1188 - 10s - 9ms/step - accuracy: 0.8606 - loss: 0.3257 - val_accuracy: 0.8607 - val_loss: 0.3195\n",
            "Epoch 4/10\n",
            "1188/1188 - 10s - 9ms/step - accuracy: 0.8700 - loss: 0.3078 - val_accuracy: 0.8660 - val_loss: 0.3106\n",
            "Epoch 5/10\n",
            "1188/1188 - 7s - 6ms/step - accuracy: 0.8780 - loss: 0.2893 - val_accuracy: 0.8749 - val_loss: 0.2942\n",
            "Epoch 6/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.8868 - loss: 0.2714 - val_accuracy: 0.8813 - val_loss: 0.2840\n",
            "Epoch 7/10\n",
            "1188/1188 - 10s - 9ms/step - accuracy: 0.8931 - loss: 0.2565 - val_accuracy: 0.8857 - val_loss: 0.2689\n",
            "Epoch 8/10\n",
            "1188/1188 - 11s - 9ms/step - accuracy: 0.8992 - loss: 0.2421 - val_accuracy: 0.8887 - val_loss: 0.2611\n",
            "Epoch 9/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.9060 - loss: 0.2293 - val_accuracy: 0.8905 - val_loss: 0.2589\n",
            "Epoch 10/10\n",
            "1188/1188 - 6s - 5ms/step - accuracy: 0.9108 - loss: 0.2166 - val_accuracy: 0.8935 - val_loss: 0.2570\n",
            "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "    dataset_size cell_type  test_acc   male_acc  female_acc\n",
            "0          23756    simple  0.899832  87.485516   91.407799\n",
            "1          23756      lstm  0.885732  82.850521   91.837409\n",
            "2          23756       gru  0.880471  87.543453   88.334435\n",
            "3          47513    simple  0.893402  86.617100   91.127767\n",
            "4          47513      lstm  0.884458  84.386617   91.110336\n",
            "5          47513       gru  0.890140  87.201275   90.203939\n",
            "6          71269    simple  0.892592  85.010383   91.771799\n",
            "7          71269      lstm  0.893644  83.462337   92.854750\n",
            "8          71269       gru  0.891188  88.257504   89.628224\n",
            "9          95026    simple  0.892823  88.515366   89.722567\n",
            "10         95026      lstm  0.897138  85.009378   92.414079\n",
            "11         95026       gru  0.893507  85.297937   91.677019\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv('name_gender.csv')\n",
        "\n",
        "# Removing non-ASCII characters\n",
        "data['name'] = data['name'].apply(lambda x: ''.join([c for c in x if ord(c) < 128]))\n",
        "\n",
        "# Mapping gender to numeric values\n",
        "data['gender'] = data['gender'].map({'M': 0, 'F': 1})\n",
        "\n",
        "# Creating a set of all unique characters\n",
        "chars = set(''.join(data['name'].values))\n",
        "char_to_index = {ch: idx + 1 for idx, ch in enumerate(chars)}  # index starts from 1\n",
        "\n",
        "# One-hot encoding the names\n",
        "def encode_name(name):\n",
        "    return [char_to_index.get(c, 0) for c in name]  # default to 0 for non-ASCII chars\n",
        "\n",
        "data['encoded_name'] = data['name'].apply(encode_name)\n",
        "\n",
        "# Padding the names to the same length (max length = 15 for example)\n",
        "max_name_length = 15\n",
        "X = pad_sequences(data['encoded_name'], maxlen=max_name_length, padding='post')\n",
        "\n",
        "# One-hot encoding the labels (gender)\n",
        "y = to_categorical(data['gender'], num_classes=2)\n",
        "\n",
        "# Function to build different RNN models\n",
        "def build_rnn_model(cell_type='simple'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(char_to_index)+1, output_dim=64, input_length=max_name_length))\n",
        "\n",
        "    if cell_type == 'simple':\n",
        "        model.add(SimpleRNN(128, activation='relu'))\n",
        "    elif cell_type == 'lstm':\n",
        "        model.add(LSTM(128, activation='relu'))\n",
        "    elif cell_type == 'gru':\n",
        "        model.add(GRU(128, activation='relu'))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(model, X, y, dataset_size):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X[:dataset_size], y[:dataset_size], test_size=0.2, random_state=42)\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
        "\n",
        "    # Evaluating overall accuracy\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Calculating class-wise accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "    male_acc = np.sum((y_pred_class == 0) & (y_test_class == 0)) / np.sum(y_test_class == 0) * 100\n",
        "    female_acc = np.sum((y_pred_class == 1) & (y_test_class == 1)) / np.sum(y_test_class == 1) * 100\n",
        "\n",
        "    return test_acc, male_acc, female_acc\n",
        "\n",
        "# Train models with different dataset sizes and report accuracies\n",
        "dataset_sizes = [int(0.25 * len(data)), int(0.5 * len(data)), int(0.75 * len(data)), len(data)]\n",
        "results = []\n",
        "\n",
        "for dataset_size in dataset_sizes:\n",
        "    for cell_type in ['simple', 'lstm', 'gru']:\n",
        "        model = build_rnn_model(cell_type)\n",
        "        test_acc, male_acc, female_acc = evaluate_model(model, X, y, dataset_size)\n",
        "        results.append({\n",
        "            'dataset_size': dataset_size,\n",
        "            'cell_type': cell_type,\n",
        "            'test_acc': test_acc,\n",
        "            'male_acc': male_acc,\n",
        "            'female_acc': female_acc\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-kJoikNAb0h",
        "outputId": "1a8f9860-89c5-4bfd-af6f-06ccaf6dea56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   dataset_size_percentage cell_type  test_acc   male_acc  female_acc\n",
            "0                      25%    simple  0.899832  87.485516   91.407799\n",
            "1                      25%      lstm  0.885732  82.850521   91.837409\n",
            "2                      25%       gru  0.880471  87.543453   88.334435\n",
            "3                      50%    simple  0.893402  86.617100   91.127767\n",
            "4                      50%      lstm  0.884458  84.386617   91.110336\n",
            "5                      50%       gru  0.890140  87.201275   90.203939\n",
            "6                      75%    simple  0.892592  85.010383   91.771799\n",
            "7                      75%      lstm  0.893644  83.462337   92.854750\n",
            "8                      75%       gru  0.891188  88.257504   89.628224\n",
            "9                     100%    simple  0.892823  88.515366   89.722567\n",
            "10                    100%      lstm  0.897138  85.009378   92.414079\n",
            "11                    100%       gru  0.893507  85.297937   91.677019\n"
          ]
        }
      ],
      "source": [
        "# Assuming `results_df` is your DataFrame with the results\n",
        "results_df['dataset_size_percentage'] = results_df['dataset_size'].apply(lambda x: f'{(x / len(data)) * 100:.0f}%')\n",
        "\n",
        "# Dropping the original 'dataset_size' column if it's not needed\n",
        "results_df = results_df.drop(columns=['dataset_size'])\n",
        "\n",
        "# Reorder columns for better presentation\n",
        "results_df = results_df[['dataset_size_percentage', 'cell_type', 'test_acc', 'male_acc', 'female_acc']]\n",
        "\n",
        "# Displaying the updated DataFrame\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement #2:**\n",
        "Train a language model using these names."
      ],
      "metadata": {
        "id": "Fbhxm9DfvCFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6e4Dt4bO_f8",
        "outputId": "3dc04a15-3c11-45b5-9016-92545da88252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8217/8217 - 31s - 4ms/step - accuracy: 0.3017 - loss: 2.2079\n",
            "Epoch 2/10\n",
            "8217/8217 - 27s - 3ms/step - accuracy: 0.3470 - loss: 2.0367\n",
            "Epoch 3/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3614 - loss: 1.9851\n",
            "Epoch 4/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3700 - loss: 1.9539\n",
            "Epoch 5/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3751 - loss: 1.9326\n",
            "Epoch 6/10\n",
            "8217/8217 - 27s - 3ms/step - accuracy: 0.3801 - loss: 1.9151\n",
            "Epoch 7/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3835 - loss: 1.9028\n",
            "Epoch 8/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3863 - loss: 1.8917\n",
            "Epoch 9/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3886 - loss: 1.8830\n",
            "Epoch 10/10\n",
            "8217/8217 - 41s - 5ms/step - accuracy: 0.3908 - loss: 1.8750\n",
            "Epoch 1/10\n",
            "1188/1188 - 7s - 6ms/step - accuracy: 0.8139 - loss: 0.4087\n",
            "Epoch 2/10\n",
            "1188/1188 - 4s - 3ms/step - accuracy: 0.8498 - loss: 0.3454\n",
            "Epoch 3/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8625 - loss: 0.3211\n",
            "Epoch 4/10\n",
            "1188/1188 - 4s - 3ms/step - accuracy: 0.8726 - loss: 0.3002\n",
            "Epoch 5/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8806 - loss: 0.2833\n",
            "Epoch 6/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.8886 - loss: 0.2678\n",
            "Epoch 7/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.8957 - loss: 0.2523\n",
            "Epoch 8/10\n",
            "1188/1188 - 4s - 3ms/step - accuracy: 0.9008 - loss: 0.2410\n",
            "Epoch 9/10\n",
            "1188/1188 - 5s - 4ms/step - accuracy: 0.9059 - loss: 0.2296\n",
            "Epoch 10/10\n",
            "1188/1188 - 4s - 4ms/step - accuracy: 0.9108 - loss: 0.2185\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n",
            "Classification Accuracy on Generated Names: 51.50%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv('name_gender.csv')\n",
        "\n",
        "# Removing non-ASCII characters\n",
        "data['name'] = data['name'].apply(lambda x: ''.join([c for c in x if ord(c) < 128]))\n",
        "\n",
        "# Mapping gender to numeric values\n",
        "data['gender'] = data['gender'].map({'M': 0, 'F': 1})\n",
        "\n",
        "# Creating a set of all unique characters\n",
        "chars = set(''.join(data['name'].values))\n",
        "char_to_index = {ch: idx + 1 for idx, ch in enumerate(chars)}  # index starts from 1\n",
        "index_to_char = {idx: ch for ch, idx in char_to_index.items()}\n",
        "\n",
        "# One-hot encoding the names\n",
        "def encode_name(name):\n",
        "    return [char_to_index.get(c, 0) for c in name]  # default to 0 for non-ASCII chars\n",
        "\n",
        "data['encoded_name'] = data['name'].apply(encode_name)\n",
        "\n",
        "# Padding the names to the same length\n",
        "max_name_length = 15\n",
        "X = pad_sequences(data['encoded_name'], maxlen=max_name_length, padding='post')\n",
        "\n",
        "# One-hot encoding the labels (gender)\n",
        "y = to_categorical(data['gender'], num_classes=2)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the LSTM model\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(char_to_index) + 1, output_dim=64, input_length=max_name_length))\n",
        "    model.add(LSTM(128, activation='relu'))\n",
        "    model.add(Dense(len(char_to_index) + 1, activation='softmax'))  # Predict next character\n",
        "    return model\n",
        "\n",
        "# Train the language model\n",
        "lm_model = build_lstm_model()\n",
        "lm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare input and output for the language model\n",
        "X_lm = []\n",
        "y_lm = []\n",
        "\n",
        "for name in data['encoded_name']:\n",
        "    for i in range(1, len(name)):\n",
        "        X_lm.append(name[:i])\n",
        "        y_lm.append(name[i])\n",
        "\n",
        "X_lm = pad_sequences(X_lm, maxlen=max_name_length, padding='post')\n",
        "y_lm = np.array(y_lm)\n",
        "\n",
        "lm_model.fit(X_lm, y_lm, epochs=10, batch_size=64, verbose=2)\n",
        "\n",
        "# Function to generate names\n",
        "def generate_name(gender, length=6):\n",
        "    name = []\n",
        "    char_idx = np.random.choice(list(char_to_index.values()))\n",
        "    for _ in range(length):\n",
        "        name.append(char_idx)\n",
        "        padded_input = pad_sequences([name], maxlen=max_name_length, padding='post')\n",
        "        next_char_prob = lm_model.predict(padded_input, verbose=0)[0]\n",
        "        char_idx = np.argmax(next_char_prob)\n",
        "        if char_idx == 0:  # End token\n",
        "            break\n",
        "    return ''.join(index_to_char.get(i, '') for i in name)\n",
        "\n",
        "# Generating 100 male and 100 female names\n",
        "male_names = [generate_name(0) for _ in range(100)]\n",
        "female_names = [generate_name(1) for _ in range(100)]\n",
        "\n",
        "# Combining generated names and true labels\n",
        "generated_names = male_names + female_names\n",
        "true_labels = [0] * 100 + [1] * 100\n",
        "\n",
        "# Encode and pad the generated names\n",
        "encoded_generated_names = [encode_name(name) for name in generated_names]\n",
        "padded_generated_names = pad_sequences(encoded_generated_names, maxlen=max_name_length, padding='post')\n",
        "\n",
        "# Loading the best LSTM classification model from Problem 1\n",
        "classification_model = Sequential()\n",
        "classification_model.add(Embedding(input_dim=len(char_to_index) + 1, output_dim=64, input_length=max_name_length))\n",
        "classification_model.add(LSTM(128, activation='relu'))\n",
        "classification_model.add(Dense(2, activation='softmax'))\n",
        "classification_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Retrain the LSTM classification model on the full dataset\n",
        "classification_model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=2)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "predictions = np.argmax(classification_model.predict(padded_generated_names), axis=1)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "print(f\"Classification Accuracy on Generated Names: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOzasa5EAjK4",
        "outputId": "62d161bd-adb1-4458-ae9c-b81f61e3517b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Male Names:\n",
            "Gerrin\n",
            "Xavion\n",
            "xishaw\n",
            "nayaha\n",
            "Karina\n",
            "Uriann\n",
            "Patric\n",
            "quandr\n",
            "imonte\n",
            "Quante\n",
            "enneri\n",
            "janael\n",
            "kennah\n",
            "Patric\n",
            "ariann\n",
            "prinal\n",
            "orinna\n",
            "fordin\n",
            "marian\n",
            "Angeli\n",
            "quandr\n",
            "Uriann\n",
            "zariah\n",
            "taniah\n",
            "kennah\n",
            "janael\n",
            "Valind\n",
            "yriahn\n",
            "Janish\n",
            "Harman\n",
            "Harman\n",
            "Quante\n",
            "Harman\n",
            "Harman\n",
            "imonte\n",
            "Farina\n",
            "Brittn\n",
            "yriahn\n",
            "Patric\n",
            "hanaya\n",
            "shanta\n",
            "Xavion\n",
            "lorien\n",
            "xishaw\n",
            "rendal\n",
            "ariann\n",
            "Raylen\n",
            "Raylen\n",
            "Xavion\n",
            "Natali\n",
            "Valind\n",
            "marian\n",
            "Janish\n",
            "Yanish\n",
            "Elizab\n",
            "wannah\n",
            "wannah\n",
            "Raylen\n",
            "Marian\n",
            "Valind\n",
            "nayaha\n",
            "Deland\n",
            "vannah\n",
            "shanta\n",
            "prinal\n",
            "Deland\n",
            "charle\n",
            "orinna\n",
            "fordin\n",
            "Janish\n",
            "Patric\n",
            "Elizab\n",
            "fordin\n",
            "Natali\n",
            "Uriann\n",
            "orinna\n",
            "Natali\n",
            "geniel\n",
            "Tamika\n",
            "Charle\n",
            "Xavion\n",
            "geniel\n",
            "Deland\n",
            "hanaya\n",
            "zariah\n",
            "enneri\n",
            "yriahn\n",
            "enneri\n",
            "Gerrin\n",
            "Walett\n",
            "Latavi\n",
            "Charle\n",
            "Shante\n",
            "Natali\n",
            "charle\n",
            "ariann\n",
            "enneri\n",
            "Charle\n",
            "Charle\n",
            "Oriann\n",
            "\n",
            "Generated Female Names:\n",
            "Farina\n",
            "Angeli\n",
            "ariann\n",
            "zariah\n",
            "marian\n",
            "Walett\n",
            "shanta\n",
            "charle\n",
            "charle\n",
            "Yanish\n",
            "Charle\n",
            "lorien\n",
            "Janish\n",
            "zariah\n",
            "Quante\n",
            "Valind\n",
            "taniah\n",
            "Gerrin\n",
            "Angeli\n",
            "Gerrin\n",
            "Tamika\n",
            "taniah\n",
            "Marian\n",
            "Latavi\n",
            "Uriann\n",
            "Latavi\n",
            "Charle\n",
            "Oriann\n",
            "briell\n",
            "geniel\n",
            "Oriann\n",
            "rendal\n",
            "taniah\n",
            "Valind\n",
            "janael\n",
            "Xavion\n",
            "zariah\n",
            "Marian\n",
            "Deland\n",
            "prinal\n",
            "imonte\n",
            "Karina\n",
            "quandr\n",
            "shanta\n",
            "orinna\n",
            "orinna\n",
            "rendal\n",
            "Yanish\n",
            "fordin\n",
            "Elizab\n",
            "Valind\n",
            "Harman\n",
            "janael\n",
            "Raylen\n",
            "Tamika\n",
            "wannah\n",
            "Walett\n",
            "zariah\n",
            "Uriann\n",
            "Valind\n",
            "orinna\n",
            "janael\n",
            "charle\n",
            "wannah\n",
            "Quante\n",
            "Angeli\n",
            "briell\n",
            "janael\n",
            "Shante\n",
            "Yanish\n",
            "Farina\n",
            "fordin\n",
            "Yanish\n",
            "Janish\n",
            "Yanish\n",
            "Zaniya\n",
            "Janish\n",
            "zariah\n",
            "prinal\n",
            "vannah\n",
            "Janish\n",
            "Charle\n",
            "Angeli\n",
            "yriahn\n",
            "charle\n",
            "Zaniya\n",
            "shanta\n",
            "Oriann\n",
            "Walett\n",
            "Gerrin\n",
            "imonte\n",
            "wannah\n",
            "Xavion\n",
            "zariah\n",
            "wannah\n",
            "Latavi\n",
            "Harman\n",
            "Patric\n",
            "Angeli\n",
            "Patric\n"
          ]
        }
      ],
      "source": [
        "# Function to generate a single name\n",
        "def generate_name(length=6):\n",
        "    name = []\n",
        "    char_idx = np.random.choice(list(char_to_index.values()))  # Random starting character\n",
        "    for _ in range(length):\n",
        "        name.append(char_idx)\n",
        "        padded_input = pad_sequences([name], maxlen=max_name_length, padding='post')\n",
        "        next_char_prob = lm_model.predict(padded_input, verbose=0)[0]\n",
        "        char_idx = np.argmax(next_char_prob)\n",
        "        if char_idx == 0:  # End token\n",
        "            break\n",
        "    return ''.join(index_to_char.get(i, '') for i in name)\n",
        "\n",
        "# Generate 100 male names and 100 female names\n",
        "male_names = [generate_name() for _ in range(100)]\n",
        "female_names = [generate_name() for _ in range(100)]\n",
        "\n",
        "# Printing male names\n",
        "print(\"Generated Male Names:\")\n",
        "print(\"\\n\".join(male_names))\n",
        "\n",
        "# Printing female names\n",
        "print(\"\\nGenerated Female Names:\")\n",
        "print(\"\\n\".join(female_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement #2a:**\n",
        "Train a language model using names starting with A, M, and Z.\n",
        "\n"
      ],
      "metadata": {
        "id": "eHqpuHw51Wgd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xREmwAq3FXpr",
        "outputId": "f9ca9abe-74f6-4059-b2a3-262741dc553f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Names: ['Aubryanahmaedph', 'Aneskaliahaharp', 'Ayedenahneelich', 'Azlichaeleneysh', 'Avenellesephopt', 'Alexandriamarie', 'Angellieterisox', 'Aubriannahbeebs', 'Angelenasederbe', 'Alaeyahshahnahm', 'Alextanderahmar', 'Antonettavephpw', 'Arrianneetteriz', 'Auttinetterephe', 'Anjelliesanahhd', 'Arnenatterieshh', 'Arnellisamareew', 'Aydricaynerethg', 'Aubreenneelesha', 'Aldoreineetteep', 'Adailahirahmeno', 'Avriellahmebebz', 'Annessandeiosap', 'Anglindariettop', 'Ashamrahmelekia', 'Alausanderrashg', 'Antonimatteephd', 'Alezeinajesephh', 'Arbaleighaelech', 'Aleekhtamaelich', 'Annieleneetethv', 'Alicondrawemedm', 'Araibahmaricesa', 'Arnolissesenosh', 'Alexandriahieph', 'Ariongalianeter', 'Akardalloneewha', 'Antonelleneberi', 'Archanjieelahmi', 'Anniaahmmariopz', 'Ashteneysenthhe', 'Adainahahbhaelb', 'Athonianetteris', 'Ambriellenahbae', 'Adonienisesephw', 'Alexandyrabeelz', 'Antwinetteaseph', 'Antianousesophu', 'Alanyahmareeeeh', 'Amushantionawse', 'Mikelahielenamg', 'Melandraephewan', 'Milandaeronaceh', 'Myrlinaheelaphh', 'Mudundratecepho', 'Madylinahmaelpc', 'Marianahlianhza', 'Markeeceerterqb', 'Mahlenieseseshq', 'Miriceeshalawhf', 'Maxneetterebets', 'Monabellaielhwe', 'Markeeesiahnael', 'Marilinahmariee', 'Michiahlahhahhm', 'Merrilenandeert', 'Mykhaelahinahbh', 'Mushleeneeteysx', 'Mariangelisanbe', 'Mijoolupardrewa', 'Margarettezephp', 'Marileanahhanoe', 'Mezoleneemaelbh', 'Maycinahamebeep', 'Mehaannahhabehh', 'Matiquelleenhac', 'Mekirabelleneqn', 'Makailynnabelel', 'Muzalichaelezha', 'Megashantiahnup', 'Monicesealedowf', 'Mathethanamoizj', 'Marnikiahahhhmb', 'Mirelleenerazhh', 'Mariahanneelidz', 'Malawaeluwandif', 'Malikahiahhnrbu', 'Marclesepharipo', 'Matonenetterozh', 'MichanzoileehnZ', 'Mellyneerettepz', 'Mabyellelechicc', 'Madelineebephez', 'Meelineelaneprd', 'Marymaiahahmmmm', 'Mihanahneeezash', 'Madvariesesenep', 'Mirtabelleshamb', 'Maxandamidaluxp', 'Marianahgnaell', 'Zyleahnahmaeyhh', 'Zuledandraephar', 'Zeyuananahhboel', 'Zuliyahahhanhdh', 'Zaiyanahhahhmbb', 'Zariannahabeerl', 'Ziaimahnaheerbz', 'Zyanteriaharvww', 'Zaredoniellnamb', 'Zayreanahhaahbh', 'Zauinahhahdahmb', 'Zikaynahhyephho', 'Zhanteyahhaibhh', 'Zackiralanietht', 'Ziliahahhhrbhfb', 'Zepharieneesteo', 'Zarrikabhellaxm', 'Zemeriahammeltq', 'Zolitsabeheshho', 'Zynnayhahirebbz', 'Zikenzabeelannp', 'Zaiyahahayhphor', 'Zykeemahimarbte', 'Zamarienattesof', 'Zyyianahnahhbhb', 'Zuinabeaphullyu', 'Zellianahreeshh', 'Zyianahehahrhhh', 'Zayleiahahnahnb', 'Zecariesonaseph', 'Zayanahanaheabb', 'Zuleeneseharrfh', 'Zamerieshaiangj', 'Zareyanahharbhh', 'Zantamedosephpo', 'Zorahiahahrhofh', 'Zenzeeshaephael', 'Zimsrahemaeship', 'Zyriannabetholp', 'Zyreanahhahmarh', 'ZaydianahhabhgM', 'Zacheirterieche', 'Zineetabareazhe', 'Zelayahabriahal', 'Zoyonisenahhelf', 'Zarethandraishb', 'Zendicianahhabb', 'Zemiahahnahmbha', 'Zethianahnahhiq', 'Zyshiaunahhram']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Function to generate a name with temperature sampling\n",
        "def generate_name_with_temperature(model, seed_char, max_length=15, temperature=1.0):\n",
        "    generated_name = [char_to_index[seed_char]]\n",
        "    for _ in range(max_length - 1):\n",
        "        padded_input = pad_sequences([generated_name], maxlen=max_name_length, padding='post')\n",
        "        predicted_probs = model.predict(padded_input, verbose=0).flatten()\n",
        "\n",
        "        # Apply temperature sampling\n",
        "        scaled_probs = np.log(predicted_probs + 1e-10) / temperature\n",
        "        exp_probs = np.exp(scaled_probs)\n",
        "        normalized_probs = exp_probs / np.sum(exp_probs)\n",
        "\n",
        "        # Sample the next character index\n",
        "        predicted_char_index = np.random.choice(len(normalized_probs), p=normalized_probs)\n",
        "\n",
        "        if predicted_char_index == 0:  # Stop if padding index is predicted\n",
        "            break\n",
        "        generated_name.append(predicted_char_index)\n",
        "    return ''.join(index_to_char[idx] for idx in generated_name)\n",
        "\n",
        "# Generating 50 diverse names\n",
        "generated_names = [\n",
        "    generate_name_with_temperature(lm_model, seed_char, temperature=0.8)\n",
        "    for seed_char in ['A', 'M', 'Z'] for _ in range(50)\n",
        "]\n",
        "print(\"Generated Names:\", generated_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the perplexity of a generated name\n",
        "def calculate_perplexity(model, name, max_length=15):\n",
        "    log_prob_sum = 0\n",
        "    for i in range(1, len(name)):\n",
        "        # Pass a list of indices, not just a single index\n",
        "        padded_input = pad_sequences([ [char_to_index[c] for c in name[:i]] ], maxlen=max_name_length, padding='post')\n",
        "\n",
        "        predicted_probs = model.predict(padded_input, verbose=0).flatten()\n",
        "        true_char_index = char_to_index[name[i]]\n",
        "\n",
        "        # Calculating log probability for the true character in the sequence\n",
        "        log_prob_sum += np.log(predicted_probs[true_char_index] + 1e-10)\n",
        "\n",
        "    # Calculating perplexity\n",
        "    perplexity = np.exp(-log_prob_sum / (len(name) - 1))\n",
        "    return perplexity\n",
        "\n",
        "# Calculating perplexity for each generated name\n",
        "perplexities = [calculate_perplexity(lm_model, name) for name in generated_names]\n",
        "\n",
        "# Output the generated names with their corresponding perplexities\n",
        "for name, perplexity in zip(generated_names, perplexities):\n",
        "    print(f\"Generated Name: {name}, Perplexity: {perplexity:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB0AVvSyzfSp",
        "outputId": "c31f0671-d0bd-441e-9afe-9853696b4caa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Name: Aanzaahahrmarpa, Perplexity: 8.35\n",
            "Generated Name: Ayannahahbhaelj, Perplexity: 4.17\n",
            "Generated Name: Audreynahnaeleq, Perplexity: 4.97\n",
            "Generated Name: Anashianahhieli, Perplexity: 4.62\n",
            "Generated Name: Alicahniabariec, Perplexity: 5.71\n",
            "Generated Name: Almarielliashob, Perplexity: 5.62\n",
            "Generated Name: Alexinahnadrbae, Perplexity: 5.73\n",
            "Generated Name: Annalinasephepe, Perplexity: 3.59\n",
            "Generated Name: Adairahmanelenz, Perplexity: 4.55\n",
            "Generated Name: Adhikondeephepp, Perplexity: 6.06\n",
            "Generated Name: AbiredlahnelhAa, Perplexity: 8.80\n",
            "Generated Name: Arnellisaneberb, Perplexity: 3.73\n",
            "Generated Name: Addisyneseneptx, Perplexity: 4.68\n",
            "Generated Name: Assreententekok, Perplexity: 8.61\n",
            "Generated Name: Antronettepopip, Perplexity: 4.40\n",
            "Generated Name: Airahmirabellau, Perplexity: 4.91\n",
            "Generated Name: Aydenonasephepp, Perplexity: 4.09\n",
            "Generated Name: Andrianettephaw, Perplexity: 3.05\n",
            "Generated Name: Alyssanderiashh, Perplexity: 2.47\n",
            "Generated Name: Angeleneeesensa, Perplexity: 4.41\n",
            "Generated Name: Angeleanetterph, Perplexity: 3.76\n",
            "Generated Name: Ateniyahahhbrhh, Perplexity: 4.65\n",
            "Generated Name: Angelithaneertt, Perplexity: 5.18\n",
            "Generated Name: Alwenaelleichea, Perplexity: 6.06\n",
            "Generated Name: Aainahiahhnafey, Perplexity: 7.99\n",
            "Generated Name: Abdullahiezechu, Perplexity: 4.31\n",
            "Generated Name: Anashannieeselx, Perplexity: 3.83\n",
            "Generated Name: Alayahnahhabhhb, Perplexity: 3.14\n",
            "Generated Name: Annayahahnaherp, Perplexity: 3.84\n",
            "Generated Name: Arwyssandroship, Perplexity: 7.51\n",
            "Generated Name: Adalineezedhabe, Perplexity: 4.85\n",
            "Generated Name: Akeyonahhaerfwj, Perplexity: 6.98\n",
            "Generated Name: Anymantorieponx, Perplexity: 8.55\n",
            "Generated Name: Annulisecaretow, Perplexity: 7.18\n",
            "Generated Name: Azarihanahbrelh, Perplexity: 6.95\n",
            "Generated Name: Auyshanneeshaep, Perplexity: 4.57\n",
            "Generated Name: Anngelicuanesep, Perplexity: 5.79\n",
            "Generated Name: Alayhahnabeedhi, Perplexity: 4.59\n",
            "Generated Name: Areenellasephre, Perplexity: 4.89\n",
            "Generated Name: Anmaluisenewetl, Perplexity: 9.75\n",
            "Generated Name: Alduricessiamej, Perplexity: 10.99\n",
            "Generated Name: Alissanyseshiar, Perplexity: 4.61\n",
            "Generated Name: Anikentaeluphis, Perplexity: 8.61\n",
            "Generated Name: Arakinatteripqu, Perplexity: 9.57\n",
            "Generated Name: Alexanderaerojh, Perplexity: 4.25\n",
            "Generated Name: Aeronahdalasheb, Perplexity: 6.59\n",
            "Generated Name: Amithandreynnad, Perplexity: 6.46\n",
            "Generated Name: ArrenahmianellA, Perplexity: 5.45\n",
            "Generated Name: Alitzirabestezq, Perplexity: 8.17\n",
            "Generated Name: Aysianahhanndes, Perplexity: 5.08\n",
            "Generated Name: Maishelynneeche, Perplexity: 3.56\n",
            "Generated Name: MelaniecezeretZ, Perplexity: 6.42\n",
            "Generated Name: Melikhailiannel, Perplexity: 5.62\n",
            "Generated Name: Melfordosesephh, Perplexity: 4.34\n",
            "Generated Name: Munabelleshophe, Perplexity: 4.81\n",
            "Generated Name: Mickallahikentf, Perplexity: 5.95\n",
            "Generated Name: Majenelieezethz, Perplexity: 6.53\n",
            "Generated Name: Mikailahahhmbhh, Perplexity: 3.02\n",
            "Generated Name: Marielynahellyq, Perplexity: 4.62\n",
            "Generated Name: Malynahahirhaar, Perplexity: 4.80\n",
            "Generated Name: Malodanielecepr, Perplexity: 4.81\n",
            "Generated Name: Millerahemeezau, Perplexity: 6.68\n",
            "Generated Name: Mishalielahbehp, Perplexity: 6.57\n",
            "Generated Name: Matalyneeperidh, Perplexity: 5.05\n",
            "Generated Name: Maricavellazewf, Perplexity: 4.66\n",
            "Generated Name: Miaraelleenabdh, Perplexity: 4.69\n",
            "Generated Name: Markesteisephaq, Perplexity: 4.64\n",
            "Generated Name: Mariahanelisech, Perplexity: 4.79\n",
            "Generated Name: Mishalenaheelbt, Perplexity: 4.00\n",
            "Generated Name: Markiellenettee, Perplexity: 3.59\n",
            "Generated Name: Markeratteepeph, Perplexity: 3.31\n",
            "Generated Name: Maarahangelaiso, Perplexity: 6.11\n",
            "Generated Name: Marickarterthip, Perplexity: 5.68\n",
            "Generated Name: Melissabezeshap, Perplexity: 4.28\n",
            "Generated Name: Maretamesesholx, Perplexity: 8.34\n",
            "Generated Name: Mordillenetteiz, Perplexity: 5.50\n",
            "Generated Name: Mahsannahellard, Perplexity: 4.46\n",
            "Generated Name: Myshangiertenne, Perplexity: 7.91\n",
            "Generated Name: Mirahnamineette, Perplexity: 6.00\n",
            "Generated Name: Mashandarienanc, Perplexity: 5.26\n",
            "Generated Name: Makaelahieghhha, Perplexity: 3.38\n",
            "Generated Name: Minordewarieazh, Perplexity: 7.77\n",
            "Generated Name: Martollyneesero, Perplexity: 6.14\n",
            "Generated Name: Molbardastewane, Perplexity: 6.99\n",
            "Generated Name: Midiethaneethes, Perplexity: 6.09\n",
            "Generated Name: Makinzeeeshabep, Perplexity: 4.00\n",
            "Generated Name: Malysenelterthq, Perplexity: 7.36\n",
            "Generated Name: MakynseyahnewlA, Perplexity: 6.06\n",
            "Generated Name: Macaylienehalha, Perplexity: 6.54\n",
            "Generated Name: Mikailahhahhhmm, Perplexity: 2.50\n",
            "Generated Name: Margyellenabeer, Perplexity: 4.11\n",
            "Generated Name: Mickieleeghaerb, Perplexity: 4.42\n",
            "Generated Name: Mynnikayonasorx, Perplexity: 9.07\n",
            "Generated Name: Mahkorahelliasz, Perplexity: 5.96\n",
            "Generated Name: Marshannieesesh, Perplexity: 3.05\n",
            "Generated Name: Mayleeneephaelp, Perplexity: 2.95\n",
            "Generated Name: Maydenaelasepha, Perplexity: 3.55\n",
            "Generated Name: Marthonaliseord, Perplexity: 6.22\n",
            "Generated Name: Mishaylahnandee, Perplexity: 3.49\n",
            "Generated Name: Mareeshanneetht, Perplexity: 3.50\n",
            "Generated Name: Zemarienetteric, Perplexity: 2.88\n",
            "Generated Name: ZykhaiyahhnyhiM, Perplexity: 6.56\n",
            "Generated Name: Zalainahahbelhb, Perplexity: 4.58\n",
            "Generated Name: Zumerionahelema, Perplexity: 4.83\n",
            "Generated Name: Zykamiahirosiao, Perplexity: 8.56\n",
            "Generated Name: Zaidahahhandhhf, Perplexity: 5.18\n",
            "Generated Name: Zarenahdesannei, Perplexity: 4.53\n",
            "Generated Name: Zaydreonatrachi, Perplexity: 7.15\n",
            "Generated Name: Zykiahrahberhzo, Perplexity: 5.68\n",
            "Generated Name: ZhaleyahahhrnMr, Perplexity: 5.88\n",
            "Generated Name: Zaionaheenahhhb, Perplexity: 4.02\n",
            "Generated Name: Zalyahahhbnoeel, Perplexity: 5.61\n",
            "Generated Name: Zelliahahreahhb, Perplexity: 4.60\n",
            "Generated Name: Zarrandallysham, Perplexity: 5.30\n",
            "Generated Name: Zepharrieneltec, Perplexity: 4.86\n",
            "Generated Name: Zaydeniahahhhmh, Perplexity: 3.32\n",
            "Generated Name: Zyyanahnaellorg, Perplexity: 4.70\n",
            "Generated Name: Zinabelleasowub, Perplexity: 6.29\n",
            "Generated Name: Zaninaheelleasg, Perplexity: 5.04\n",
            "Generated Name: Zontoryannabeel, Perplexity: 4.86\n",
            "Generated Name: Zynayahnabeelln, Perplexity: 4.08\n",
            "Generated Name: Zamirabalinetcn, Perplexity: 7.29\n",
            "Generated Name: Zailynneeasephh, Perplexity: 2.58\n",
            "Generated Name: Zariyaneosephwa, Perplexity: 5.36\n",
            "Generated Name: Zaylynaheepehph, Perplexity: 5.21\n",
            "Generated Name: Zimuriesehaship, Perplexity: 6.02\n",
            "Generated Name: Zaetandephiasox, Perplexity: 6.11\n",
            "Generated Name: Zayannaherahbhj, Perplexity: 3.54\n",
            "Generated Name: Zayleeneepterrd, Perplexity: 4.16\n",
            "Generated Name: Zekiahahnhahnab, Perplexity: 4.20\n",
            "Generated Name: Zaidalahihahmy, Perplexity: 4.86\n",
            "Generated Name: Zonellianneerdx, Perplexity: 4.84\n",
            "Generated Name: Zahileighaangao, Perplexity: 4.93\n",
            "Generated Name: Zahairahhaarhup, Perplexity: 3.78\n",
            "Generated Name: Zaybenajephenbr, Perplexity: 10.95\n",
            "Generated Name: Zahidahnahephar, Perplexity: 3.30\n",
            "Generated Name: Zellisaneerethd, Perplexity: 3.89\n",
            "Generated Name: Zelynneeseephha, Perplexity: 2.99\n",
            "Generated Name: Zkaylieahnahhhh, Perplexity: 4.98\n",
            "Generated Name: Zaiyahnahneellf, Perplexity: 3.39\n",
            "Generated Name: Zaeshahnandwasj, Perplexity: 9.03\n",
            "Generated Name: Zenorahahiephae, Perplexity: 4.21\n",
            "Generated Name: Zariyahanahhbhb, Perplexity: 2.90\n",
            "Generated Name: Zakarriannahbrr, Perplexity: 3.59\n",
            "Generated Name: Zhailynahhabeel, Perplexity: 3.44\n",
            "Generated Name: Zyianahnahahbhh, Perplexity: 2.63\n",
            "Generated Name: Zyairahmareepee, Perplexity: 4.21\n",
            "Generated Name: Zaelynneecephne, Perplexity: 4.14\n",
            "Generated Name: Zaydinneesephae, Perplexity: 2.91\n",
            "Generated Name: Zacheyanneethrp, Perplexity: 4.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TP1LnQbo2_EA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
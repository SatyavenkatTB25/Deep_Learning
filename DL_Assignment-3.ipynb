{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVmj6DIOlLHG"
      },
      "source": [
        "#### Problem statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVzd3_9lLHI"
      },
      "source": [
        "Predict the political party from the tweet text and the handle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhIHuKQhlLHI"
      },
      "source": [
        "#### Data description\n",
        "This dataset has three columns - label (party name), twitter handle, tweet text\n",
        "\n",
        "\n",
        "#### Problem Description:\n",
        "\n",
        "Design a feed forward deep neural network to predict the political party using the pytorch or tensorflow.\n",
        "Build two models\n",
        "\n",
        "1. Without using the handle\n",
        "\n",
        "2. Using the handle\n",
        "\n",
        "\n",
        "#### Deliverables\n",
        "\n",
        "- Report the performance on the test set.\n",
        "\n",
        "- Try multiple models and with different hyperparameters. Present the results of each model on the test set. No need to create a dev set.\n",
        "\n",
        "- Experiment with:\n",
        "    -L2 and dropout regularization techniques\n",
        "    -SGD, RMSProp and Adamp optimization techniques\n",
        "\n",
        "\n",
        "\n",
        "- Creating a fixed-sized vocabulary: Give a unique id to each word in your selected vocabulary and use it as the input to the network\n",
        "\n",
        "    - Option 1: Feedforward networks can only handle fixed-sized inputs. You can choose to have a fixed-sized K words from the tweet text (e.g. the first K word, randomly selected K word etc.). K can be a hyperparameter.\n",
        "\n",
        "    - Option 2: you can choose top N (e.g. N=1000) frequent words from the dataset and use an N-sized input layer. If a word is present in a tweet, pass the id, 0 otherwise\n",
        "    \n",
        "    -  Clearly state your design choices and assumptions. Think about the pros and cons of each option.\n",
        "\n",
        "\n",
        "\n",
        "<b> Tabulate your results, either at the end of the code file or in the text box on the submission page. The final result should have:</b>\n",
        "\n",
        "1. Experiment description\n",
        "\n",
        "2. Hyperparameter used and their values\n",
        "\n",
        "3. Performance on the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "thJRgy0fuIC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Making sure the Tweet column is of string type\n",
        "train_df['Tweet'] = train_df['Tweet'].astype(str)\n",
        "test_df['Tweet'] = test_df['Tweet'].astype(str)\n",
        "\n",
        "# Handling the missing values in the Handle column\n",
        "train_df['Handle'] = train_df['Handle'].fillna('')\n",
        "test_df['Handle'] = test_df['Handle'].fillna('')\n",
        "\n",
        "# Function to create a vocabulary from tweets\n",
        "def create_vocabulary(tweets, max_size=1000):\n",
        "    words = ' '.join(tweets).split()\n",
        "    freq = Counter(words)\n",
        "    vocab = {word: idx + 1 for idx, (word, _) in enumerate(freq.most_common(max_size))}  # Start indexing from 1\n",
        "    return vocab\n",
        "\n",
        "# Creating vocabulary from the train dataset\n",
        "vocab = create_vocabulary(train_df['Tweet'])\n",
        "vocab_size = len(vocab) + 1  # +1 for padding\n",
        "\n",
        "# Function to encode tweets and handles into numerical IDs\n",
        "def encode_tweet(tweet, vocab, max_length):\n",
        "    tweet_ids = [vocab.get(word, 0) for word in tweet.split()]\n",
        "    return tweet_ids[:max_length] + [0] * (max_length - len(tweet_ids))\n",
        "\n",
        "def encode_handle(handle, max_length):\n",
        "    handle_ids = [ord(char) for char in handle]  # using ASCII values of characters\n",
        "    return handle_ids[:max_length] + [0] * (max_length - len(handle_ids))\n",
        "\n",
        "max_length = 10  # Adjusting this to our desired fixed size\n",
        "\n",
        "# Encoding the tweets and handles\n",
        "train_df['Encoded'] = train_df['Tweet'].apply(lambda x: encode_tweet(x, vocab, max_length))\n",
        "train_df['Encoded_Handle'] = train_df['Handle'].apply(lambda x: encode_handle(x, max_length))\n",
        "test_df['Encoded'] = test_df['Tweet'].apply(lambda x: encode_tweet(x, vocab, max_length))\n",
        "test_df['Encoded_Handle'] = test_df['Handle'].apply(lambda x: encode_handle(x, max_length))\n",
        "\n",
        "# Converting the labels to numerical format\n",
        "label_mapping = {label: idx for idx, label in enumerate(train_df['Party'].unique())}\n",
        "train_df['Party'] = train_df['Party'].map(label_mapping)\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgCdqRJn3-Ny",
        "outputId": "4a7b71e2-9627-49d2-988e-841b1ddfbffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Unnamed: 0  Party         Handle  \\\n",
            "0          0      0  RepDarrenSoto   \n",
            "1          1      0  RepDarrenSoto   \n",
            "2          2      0  RepDarrenSoto   \n",
            "3          3      0  RepDarrenSoto   \n",
            "4          4      0  RepDarrenSoto   \n",
            "\n",
            "                                               Tweet  \\\n",
            "0  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
            "1  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
            "2  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
            "3  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
            "4  RT @Vegalteno: Hurricane season starts on June...   \n",
            "\n",
            "                                   Encoded  \\\n",
            "0  [108, 197, 0, 148, 2, 0, 155, 2, 63, 0]   \n",
            "1          [8, 0, 0, 0, 0, 0, 0, 0, 0, 10]   \n",
            "2       [8, 0, 0, 0, 16, 0, 0, 34, 879, 0]   \n",
            "3     [8, 0, 0, 12, 0, 876, 67, 7, 304, 1]   \n",
            "4         [8, 0, 0, 0, 0, 9, 0, 0, 859, 0]   \n",
            "\n",
            "                                   Encoded_Handle  \n",
            "0  [82, 101, 112, 68, 97, 114, 114, 101, 110, 83]  \n",
            "1  [82, 101, 112, 68, 97, 114, 114, 101, 110, 83]  \n",
            "2  [82, 101, 112, 68, 97, 114, 114, 101, 110, 83]  \n",
            "3  [82, 101, 112, 68, 97, 114, 114, 101, 110, 83]  \n",
            "4  [82, 101, 112, 68, 97, 114, 114, 101, 110, 83]  \n",
            "   Unnamed: 0     Party       Handle  \\\n",
            "0        1009  Democrat  RepBarragan   \n",
            "1        1025  Democrat  RepBarragan   \n",
            "2        1029  Democrat  RepBarragan   \n",
            "3        1031  Democrat  RepBarragan   \n",
            "4        1035  Democrat  RepBarragan   \n",
            "\n",
            "                                               Tweet  \\\n",
            "0  Join me next Friday, May 18 in #Lynwood for ou...   \n",
            "1  The administration announced its plan today to...   \n",
            "2  Today’s @SouthGateCAgov’s JAA Opening Day Cere...   \n",
            "3  Great visit @Compton_YB! TY for creating a pos...   \n",
            "4  Tune into my Water Quality Town Hall live feed...   \n",
            "\n",
            "                                      Encoded  \\\n",
            "0      [296, 70, 247, 0, 349, 0, 5, 0, 7, 13]   \n",
            "1  [20, 718, 449, 139, 236, 46, 2, 0, 0, 278]   \n",
            "2        [0, 0, 0, 0, 214, 0, 29, 40, 88, 80]   \n",
            "3         [55, 200, 0, 0, 7, 0, 6, 0, 0, 258]   \n",
            "4   [211, 137, 21, 0, 0, 693, 603, 207, 0, 9]   \n",
            "\n",
            "                                  Encoded_Handle  \n",
            "0  [82, 101, 112, 66, 97, 114, 114, 97, 103, 97]  \n",
            "1  [82, 101, 112, 66, 97, 114, 114, 97, 103, 97]  \n",
            "2  [82, 101, 112, 66, 97, 114, 114, 97, 103, 97]  \n",
            "3  [82, 101, 112, 66, 97, 114, 114, 97, 103, 97]  \n",
            "4  [82, 101, 112, 66, 97, 114, 114, 97, 103, 97]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Dataset class for tweets with handles\n",
        "class TweetWithHandleDataset(Dataset):\n",
        "    def __init__(self, encodings, handles, labels):\n",
        "        self.encodings = encodings\n",
        "        self.handles = handles\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings[idx], dtype=torch.long),\n",
        "            'handles': torch.tensor(self.handles[idx], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Defining the Feedforward Neural Network that includes handle processing\n",
        "class FeedForwardNNWithHandle(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate):\n",
        "        super(FeedForwardNNWithHandle, self).__init__()\n",
        "        self.tweet_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.handle_embedding = nn.Embedding(256, embedding_dim)\n",
        "        self.fc1 = nn.Linear(max_length * embedding_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, handle_ids):\n",
        "        tweet_embeds = self.tweet_embedding(input_ids)\n",
        "        handle_embeds = self.handle_embedding(handle_ids)\n",
        "        x = torch.cat((tweet_embeds.view(tweet_embeds.size(0), -1), handle_embeds.view(handle_embeds.size(0), -1)), dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Defining the Feedforward Neural Network that does NOT include handle processing\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(max_length * embedding_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embeds = self.embedding(input_ids)\n",
        "        x = embeds.view(embeds.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "aiL7b8j34JGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test datasets\n",
        "train_dataset_with_handle = TweetWithHandleDataset(\n",
        "    list(train_df['Encoded']),\n",
        "    list(train_df['Encoded_Handle']),\n",
        "    list(train_df['Party'])\n",
        ")\n",
        "train_dataset_without_handle = TweetWithHandleDataset(\n",
        "    list(train_df['Encoded']),\n",
        "    [[] for _ in range(len(train_df))],\n",
        "    list(train_df['Party'])\n",
        ")\n",
        "\n",
        "test_dataset = TweetWithHandleDataset(\n",
        "    list(test_df['Encoded']),\n",
        "    list(test_df['Encoded_Handle']),\n",
        "    [0] * len(test_df)\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "train_loader_with_handle = DataLoader(train_dataset_with_handle, batch_size=32, shuffle=True)\n",
        "train_loader_without_handle = DataLoader(train_dataset_without_handle, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "oHiSecjf4MFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Hyperparameters\n",
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "output_dim = len(label_mapping)  # No. of unique political parties\n",
        "dropout_rate = 0.5\n",
        "\n",
        "# Initializing models with handle & Without Handle\n",
        "model_with_handle = FeedForwardNNWithHandle(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate)\n",
        "model_without_handle = FeedForwardNN(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining optimizers with L2 regularization\n",
        "optimizer_with_handle_adam = optim.Adam(model_with_handle.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "optimizer_without_handle_adam = optim.Adam(model_without_handle.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "optimizer_with_handle_sgd = optim.SGD(model_with_handle.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "optimizer_without_handle_sgd = optim.SGD(model_without_handle.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "optimizer_with_handle_rmsprop = optim.RMSprop(model_with_handle.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "optimizer_without_handle_rmsprop = optim.RMSprop(model_without_handle.parameters(), lr=0.001, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "1-Jt_6e44O1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the function\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=5, use_handle=True):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            if use_handle:\n",
        "                input_ids = batch['input_ids']\n",
        "                handle_ids = batch['handles']\n",
        "                outputs = model(input_ids, handle_ids)\n",
        "            else:\n",
        "                input_ids = batch['input_ids']\n",
        "                outputs = model(input_ids)\n",
        "            loss = criterion(outputs, batch['labels'])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_loader, use_handle=True):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            if use_handle:\n",
        "                input_ids = batch['input_ids']\n",
        "                handle_ids = batch['handles']\n",
        "                outputs = model(input_ids, handle_ids)\n",
        "            else:\n",
        "                input_ids = batch['input_ids']\n",
        "                outputs = model(input_ids)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.numpy())\n",
        "            all_labels.extend(batch['labels'].numpy())\n",
        "\n",
        "    return accuracy_score(all_labels, all_predictions)\n"
      ],
      "metadata": {
        "id": "MgoGH52j4RrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and assess the model with the handle using the Adam optimizer\n",
        "train_model(model_with_handle, train_loader_with_handle, criterion, optimizer_with_handle_adam)\n",
        "accuracy_with_handle_adam = evaluate_model(model_with_handle, test_loader, use_handle=True)\n",
        "print(f'Accuracy with handle (Adam): {accuracy_with_handle_adam:.4f}')\n",
        "\n",
        "# Train and assess the model without handle using the Adam optimizer\n",
        "train_model(model_without_handle, train_loader_without_handle, criterion, optimizer_without_handle_adam, use_handle=False)\n",
        "accuracy_without_handle_adam = evaluate_model(model_without_handle, test_loader, use_handle=False)\n",
        "print(f'Accuracy without handle (Adam): {accuracy_without_handle_adam:.4f}')\n",
        "\n",
        "# Train and evaluate the model with handle, without Handle using SGD and RMSProp optimizers\n",
        "train_model(model_with_handle, train_loader_with_handle, criterion, optimizer_with_handle_sgd)\n",
        "accuracy_with_handle_sgd = evaluate_model(model_with_handle, test_loader, use_handle=True)\n",
        "print(f'Accuracy with handle (SGD): {accuracy_with_handle_sgd:.4f}')\n",
        "\n",
        "train_model(model_without_handle, train_loader_without_handle, criterion, optimizer_without_handle_sgd, use_handle=False)\n",
        "accuracy_without_handle_sgd = evaluate_model(model_without_handle, test_loader, use_handle=False)\n",
        "print(f'Accuracy without handle (SGD): {accuracy_without_handle_sgd:.4f}')\n",
        "\n",
        "train_model(model_with_handle, train_loader_with_handle, criterion, optimizer_with_handle_rmsprop)\n",
        "accuracy_with_handle_rmsprop = evaluate_model(model_with_handle, test_loader, use_handle=True)\n",
        "print(f'Accuracy with handle (RMSProp): {accuracy_with_handle_rmsprop:.4f}')\n",
        "\n",
        "train_model(model_without_handle, train_loader_without_handle, criterion, optimizer_without_handle_rmsprop, use_handle=False)\n",
        "accuracy_without_handle_rmsprop = evaluate_model(model_without_handle, test_loader, use_handle=False)\n",
        "print(f'Accuracy without handle (RMSProp): {accuracy_without_handle_rmsprop:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snU9Qy694Umq",
        "outputId": "673b5a59-ddbb-4dc6-a377-ec2e86ce7c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.10704672720244447\n",
            "Epoch 2, Loss: 0.02268048529416957\n",
            "Epoch 3, Loss: 0.021294670939854255\n",
            "Epoch 4, Loss: 0.019458702005206052\n",
            "Epoch 5, Loss: 0.018997185375999696\n",
            "Accuracy with handle (Adam): 0.4850\n",
            "Epoch 1, Loss: 0.6880309031337984\n",
            "Epoch 2, Loss: 0.6544161152587921\n",
            "Epoch 3, Loss: 0.6271105544240896\n",
            "Epoch 4, Loss: 0.6161232080771123\n",
            "Epoch 5, Loss: 0.6094470341143711\n",
            "Accuracy without handle (Adam): 0.5067\n",
            "Epoch 1, Loss: 0.016528541567201686\n",
            "Epoch 2, Loss: 0.016291438572187837\n",
            "Epoch 3, Loss: 0.01617888709261888\n",
            "Epoch 4, Loss: 0.015949408589658945\n",
            "Epoch 5, Loss: 0.015779534401468266\n",
            "Accuracy with handle (SGD): 0.4896\n",
            "Epoch 1, Loss: 0.5869291955109373\n",
            "Epoch 2, Loss: 0.5836974203953699\n",
            "Epoch 3, Loss: 0.5814611516856854\n",
            "Epoch 4, Loss: 0.5802821217525178\n",
            "Epoch 5, Loss: 0.5794321566466135\n",
            "Accuracy without handle (SGD): 0.4776\n",
            "Epoch 1, Loss: 0.020346484979414756\n",
            "Epoch 2, Loss: 0.019321491015070965\n",
            "Epoch 3, Loss: 0.019143940945155483\n",
            "Epoch 4, Loss: 0.019100866733100377\n",
            "Epoch 5, Loss: 0.018486161308601468\n",
            "Accuracy with handle (RMSProp): 0.5063\n",
            "Epoch 1, Loss: 0.6097698862784453\n",
            "Epoch 2, Loss: 0.5976240152416908\n",
            "Epoch 3, Loss: 0.5889958546935752\n",
            "Epoch 4, Loss: 0.5803293490325938\n",
            "Epoch 5, Loss: 0.5719455413313831\n",
            "Accuracy without handle (RMSProp): 0.4228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results:-\n",
        "results = {\n",
        "    \"Model\": [\"With Handle (Adam)\", \"Without Handle (Adam)\",\n",
        "              \"With Handle (SGD)\", \"Without Handle (SGD)\",\n",
        "              \"With Handle (RMSProp)\", \"Without Handle (RMSProp)\"],\n",
        "    \"Accuracy\": [accuracy_with_handle_adam, accuracy_without_handle_adam,\n",
        "                 accuracy_with_handle_sgd, accuracy_without_handle_sgd,\n",
        "                 accuracy_with_handle_rmsprop, accuracy_without_handle_rmsprop]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU6RudGA5rHE",
        "outputId": "e53566b6-90ec-4431-f1a2-d3ee42d53106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Model  Accuracy\n",
            "0        With Handle (Adam)  0.484992\n",
            "1     Without Handle (Adam)  0.506703\n",
            "2         With Handle (SGD)  0.489582\n",
            "3      Without Handle (SGD)  0.477561\n",
            "4     With Handle (RMSProp)  0.506338\n",
            "5  Without Handle (RMSProp)  0.422847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "\n",
        "Two models were designed to predict the political party based on tweets:\n",
        "1. **Model with Handle**: Incorporates both the tweet content and the handle associated with the tweet.\n",
        "2. **Model without Handle**: Uses only the tweet content for prediction.\n",
        "\n",
        "Both models were tested using three optimization techniques: Adam, SGD, and RMSProp, with L2 regularization and dropout to prevent overfitting.\n",
        "\n",
        "### Hyperparameters\n",
        "\n",
        "The hyperparameters used across all experiments are as follows:\n",
        "\n",
        "- **Embedding dimension**: 64\n",
        "- **Hidden dimension**: 128\n",
        "- **Dropout rate**: 0.5\n",
        "- **Batch size**: 32\n",
        "- **Output dimension**: Based on the number of unique political parties\n",
        "- **Learning rate**:\n",
        "    - Adam: 0.001\n",
        "    - SGD: 0.01\n",
        "    - RMSProp: 0.001\n",
        "- **L2 regularization (weight decay)**: 1e-4\n",
        "\n",
        "### Performance on the Test Set\n",
        "\n",
        "| Model                    | Accuracy  |\n",
        "|---------------------------|-----------|\n",
        "| With Handle (Adam)         | 0.484992  |\n",
        "| Without Handle (Adam)      | 0.506703  |\n",
        "| With Handle (SGD)          | 0.489582  |\n",
        "| Without Handle (SGD)       | 0.477561  |\n",
        "| With Handle (RMSProp)      | 0.506338  |\n",
        "| Without Handle (RMSProp)   | 0.422847  |\n",
        "\n",
        "### Summary of Results\n",
        "\n",
        "- The **Without Handle (Adam)** model achieved the highest accuracy on the test set, with an accuracy of **0.506703**.\n",
        "- The **With Handle (RMSProp)** model performed similarly well, with an accuracy of **0.506338**.\n",
        "- The **With Handle (Adam)** and **With Handle (SGD)** models had comparable performance, both achieving around **0.484992** and **0.489582**, respectively.\n",
        "- The **Without Handle (RMSProp)** model had the lowest accuracy at **0.422847**.\n"
      ],
      "metadata": {
        "id": "-UfHKnmKT69U"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
